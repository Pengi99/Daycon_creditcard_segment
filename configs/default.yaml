data:
  path_dir: "/Users/jojongho/KDT/Daycon_credit/dataset"
  months: ["07", "08", "09", "10", "11", "12"]

split:
  test_size: 0.3
  random_state: 42

features:
  na_ratio: 0.8
  select: false
  select_csv: "selected_features.csv"

select:
  top_n: 200
  corr_threshold: 0.99
  slice_n: 10          # 데이터 샘플링 분할 수 (1이면 전체 데이터, 5면 1/5 사용)
  random_state: 42    # 샘플링 시드
  mandatory_features:
    - 기준년월
    - ID
    - Segment
  rf_params:
    n_estimators: 400       # Number of trees. Increase (100-1000+) for more stable importances.
    max_depth: null         # Max tree depth. null = no limit; lower value reduces overfitting.
    min_samples_leaf: 2     # Min samples per leaf. Increase to smooth predictions.
    max_features: "sqrt"    # Features considered at each split: "sqrt", "log2", or float.
    random_state: 42        # Seed for reproducibility.
    oob_score: True
    # Optional tuning parameters:
    # criterion: "gini"       # Splitting criterion: "gini" or "entropy".
    # min_samples_split: 2    # Min samples to split a node (increase to prevent splits on low-sample nodes).
    # bootstrap: true         # Use bootstrap samples; false uses whole dataset for each tree.
    # n_jobs: -1              # Number of jobs to run in parallel (-1 uses all cores).
  output_csv: "/Users/jojongho/KDT/Daycon_credit/dataset/features/selected_features.csv"

model:
  name: "lgbm"
  params:
    objective: "multiclass"
    num_class: 5
    learning_rate: 0.1
    n_estimators: 100

output:
  file_name: "submit.csv"
  result_dir: "results" 